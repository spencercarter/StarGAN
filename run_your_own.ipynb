{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run your own images through StarGAN\n",
    "By Spencer Carter\n",
    "\n",
    "\n",
    "Last updated: 2/3/18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "from torch.autograd import grad\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import transforms\n",
    "from model import Generator\n",
    "from model import Discriminator\n",
    "from PIL import Image\n",
    "from model import Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainedGenerator(object):\n",
    "    '''TrainedGenerator class loads up the model (model_save_path) from a .pth file\n",
    "    and provides a method to score individual images from a file and list of\n",
    "    ground truth attributes.\n",
    "    '''\n",
    "    def __init__(self, model_save_path, cuda=True):\n",
    "        \n",
    "        self.model_save_path = model_save_path\n",
    "        self.cuda = cuda and torch.cuda.is_available()\n",
    "        \n",
    "        # Initialize model\n",
    "        self.G = Generator()\n",
    "        self.G.load_state_dict(torch.load(self.model_save_path))\n",
    "        print(\"Generator weights loaded\")\n",
    "        \n",
    "        # Cuda\n",
    "        if self.cuda and torch.cuda.is_available():\n",
    "            self.G = self.G.cuda()\n",
    "            print(\"Using GPU\")\n",
    "        else:\n",
    "            print(\"Using CPU\")\n",
    "        \n",
    "        # Assuming fixed attributes, but could make these inputs to the class\n",
    "        self.crop_size = 178\n",
    "        self.image_size = 128\n",
    "        self.image_shape = (3, self.image_size, self.image_size)\n",
    "        self.transform = transforms.Compose([\n",
    "                    transforms.CenterCrop(self.crop_size),\n",
    "                    transforms.Resize(self.image_size),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "        \n",
    "    def denorm(self, x):\n",
    "        '''Lift and load from solver.py'''\n",
    "        out = (x + 1) / 2\n",
    "        return out.clamp_(0, 1)\n",
    "\n",
    "    def to_var(self, x, volatile=False):\n",
    "        '''Lift and load from solver.py'''\n",
    "        if self.cuda:\n",
    "            x = x.cuda()\n",
    "        return Variable(x, volatile=volatile)\n",
    "\n",
    "    def transform_img(self, img):\n",
    "        '''Apply the transformations StarGAN uses,\n",
    "        and reshape the tensor from \n",
    "        (3, 128, 128) -> (1, 3 ,128, 128)\n",
    "        since the model is looking for a batch size\n",
    "        '''\n",
    "        tf = self.transform(img).view(1,*self.image_shape)\n",
    "        return self.to_var(tf)\n",
    "\n",
    "    def score_image(self, in_file, out_path, black_hair=1, blond_hair=0, brown_hair=1, male=0, young=1):\n",
    "        ''' Take in an image file, and the output directory, \n",
    "        along with the 5 ground truth attributes for the model\n",
    "        to perturb.\n",
    "        self: Remove hair color. It's effectively not used.\n",
    "        '''\n",
    "        img = Image.open(in_file)\n",
    "\n",
    "        real_x = self.transform_img(img)\n",
    "\n",
    "        attr_list = [black_hair*1, blond_hair*1, brown_hair*1, male*1, young*1] # yeah yeah... implicit conversion is bad\n",
    "\n",
    "        target_c_list = []\n",
    "        for j, val in enumerate(attr_list):\n",
    "            if val not in [0, 1]:\n",
    "                val=0\n",
    "            target_c = torch.Tensor(attr_list)\n",
    "            if j in (0,1,2):\n",
    "                target_c[0] = 0\n",
    "                target_c[1] = 0\n",
    "                target_c[2] = 0\n",
    "            target_c[j] = 1-val\n",
    "            target_c_list.append(self.to_var(target_c.view(1,-1), volatile=True))\n",
    "\n",
    "        fake_image_list = [real_x]\n",
    "        for target_c in target_c_list:\n",
    "            fake_image_list.append(self.G(real_x, target_c))\n",
    "\n",
    "        fake_images = torch.cat(fake_image_list, dim=3)\n",
    "        name = in_file.split('/')[-1].split('.')[0]\n",
    "        save_path = os.path.join(out_path, '{}_fake.png'.format(name))\n",
    "        save_image(self.denorm(fake_images.data), save_path, nrow=1, padding=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator weights loaded\n",
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "gen = TrainedGenerator('./stargan_celebA/models/20_1000_G.pth', cuda=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below is the quick and dirty approach... for many images, use the CelebA approach and have a delimited text file containing the GT attributes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = './data/self_data/'\n",
    "out_path = './stargan_celebA/self_results/'\n",
    "\n",
    "# ['Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Male', 'Young']\n",
    "friends = []\n",
    "friends.append(['spencer_1.jpg', 0, 0, 1, 1, 1])\n",
    "friends.append(['spencer_2.jpg', 0, 0, 1, 1, 1])\n",
    "friends.append(['spencer_3.jpg', 0, 0, 1, 1, 1])\n",
    "\n",
    "friends.append(['lucy_1.jpg', 0, 0, 1, 0, 1])\n",
    "friends.append(['lucy_2.jpg', 0, 0, 1, 0, 1])\n",
    "friends.append(['lucy_3.jpg', 0, 0, 1, 0, 1])\n",
    "\n",
    "friends.append(['tron_1.jpg', 0, 0, 1, 1, 1])\n",
    "friends.append(['tron_2.jpg', 0, 0, 1, 1, 1])\n",
    "\n",
    "friends.append(['doss_1.jpg', 0, 0, 1, 0, 1])\n",
    "friends.append(['doss_2.jpg', 0, 0, 1, 0, 1])\n",
    "\n",
    "friends.append(['brian_1.jpg', 1, 0, 0, 1, 1])\n",
    "friends.append(['brian_2.jpg', 1, 0, 0, 1, 1])\n",
    "\n",
    "friends.append(['ben_1.jpg', 1, 0, 0, 1, 1])\n",
    "\n",
    "friends.append(['katy_1.jpg', 1, 0, 0, 0, 1])\n",
    "\n",
    "friends.append(['audra_1.jpg', 1, 0, 0, 0, 1])\n",
    "friends.append(['audra_2.jpg', 1, 0, 0, 0, 1])\n",
    "\n",
    "friends.append(['ethan_1.jpg', 0, 0, 1, 1, 1])\n",
    "\n",
    "friends.append(['ryan_1.jpg', 0, 0, 1, 1, 1])\n",
    "friends.append(['ryan_2.jpg', 0, 0, 1, 1, 1])\n",
    "\n",
    "friends.append(['nga_1.jpg', 1, 0, 0, 0, 1])\n",
    "\n",
    "friends.append(['abby_1.jpg', 0, 0, 1, 0, 1])\n",
    "friends.append(['abby_2.jpg', 0, 0, 1, 0, 1])\n",
    "\n",
    "for friend in friends:\n",
    "    f_in = os.path.join(in_path, friend[0])\n",
    "    gen.score_image(f_in, out_path, *friend[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
